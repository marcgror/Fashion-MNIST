{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37764bitmyenvconda966a52bc464c4d8495af3e092d2af30f",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I perform a hyperparameter tuning on a CNN trained with the Fashion MNIST dataset. Instead of using Hyperopt, Random Search or Grid Search as in the MNIST notebook, in this case I chose Optuna as hyperparameter optimization framework."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading the data\n",
    "We start by reading and saving the train and test datasets, directly from the keras package:"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During all the notebook, we will use only the train dataset, as the test set is used only at the end, when evaluating the final/tuned model.\n",
    "\n",
    "The shapes of the sets are:"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "X_train_full.shape, y_train_full.shape,  X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing the data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due the large amount of data available, we select the first 5000 instances to speed up the process. We also select the last 5000 instances of the train set as validation data for the Neural Network:"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train_full[:5000] / 255.0, X_train_full[55000:] / 255.0\n",
    "y_train, y_valid = y_train_full[:5000] , y_train_full[55000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((5000, 28, 28), (5000, 28, 28))"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot one of the instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 231.84 231.84\" width=\"231.84pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 231.84 \r\nL 231.84 231.84 \r\nL 231.84 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g clip-path=\"url(#p0c66dce13c)\">\r\n    <image height=\"218\" id=\"image1fc01c322f\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.64\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p0c66dce13c\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"7.2\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAKRElEQVR4nO3dy2/N3R/F8d3HpbSSaqXu1bgNOqiIqNAhISoxMDc1MiZh4C8wNxFMS4iRSCUGNKQuIQYI4hZxJ6rUtTyDX36/Ub9rPTkn/VnN834Nu7JPz6UrJ+kne++G379/FwB5/vrTTwDA+CgnEIpyAqEoJxCKcgKhppqcf+UCE69hvB/yzQmEopxAKMoJhKKcQCjKCYSinEAoygmEopxAKMoJhKKcQCjKCYSinEAoygmEopxAKMoJhKKcQCjKCYSinEAoygmEopxAKMoJhKKcQCh3NCb+z9zFUg0N456i+I+NjIzIfHBwsDLr6+ur63e71zY2NlaZTZ36Z/9U67nwq9bPjG9OIBTlBEJRTiAU5QRCUU4gFOUEQlFOIBRzzjC/fv2S+ZQpU2T+4MEDmR8+fFjmM2fOrMyam5vl2hkzZsh83bp1Mq9nlunmkO59devreW5qfltK9WfKNycQinICoSgnEIpyAqEoJxCKcgKhKCcQijlnmFpnYv91/vx5mZ87d07mHR0dldm3b9/k2tHRUZkPDAzIfNeuXZXZvHnz5Fq3Z9K9b86nT58qs7/+0t9xTU1NNf1OvjmBUJQTCEU5gVCUEwhFOYFQlBMIRTmBUMw5w0yfPr2u9VevXpX548ePZa72Pbo9kVu2bJH5jRs3ZL53797KbO3atXJtd3e3zLu6umR+5coVmav3tbe3V67dsGGDzFtaWsb9Od+cQCjKCYSinEAoygmEopxAKMoJhGowRwLWfu8ZKqn33G19clu+1DiilFI+fPgg82nTplVmbmuU09PTI/MVK1ZUZm7E5I62fPnypczd0ZfqWM8TJ07Itbt375b5xo0bx/3Q+eYEQlFOIBTlBEJRTiAU5QRCUU4gFOUEQjHnrIGbqdXDzTnXr18vc7clzFGvzR0v2djYWNfvVlcIuvdlzZo1Ml+5cqXM3Ws7e/ZsZfbw4UO59vnz5zIvpTDnBCYTygmEopxAKMoJhKKcQCjKCYSinEAojsasgZu5TaTW1laZv3jxQuYzZ86Uubrm78ePH3KtuiavFD3HLKWUL1++VGbuPR8cHJT5pUuXZO5m169evarMtm7dKtfWim9OIBTlBEJRTiAU5QRCUU4gFOUEQlFOIBRzzklmdHRU5mNjYzJ31/ipOej8+fPl2jlz5sjc7TVV5+K6OaR73WqG6n53KXq/57Nnz+TaWvHNCYSinEAoygmEopxAKMoJhKKcQCjKCYRizlkDN3Nzs0Q1M3N7It0ZqO7sWHfP5ffv32t+7ObmZpkPDw/LXM1J3XxXPe9SSpk1a5bMP378KPPu7u7K7PPnz3LttWvXZL527dpxf843JxCKcgKhKCcQinICoSgnEIpyAqEYpdTAHdPoti+pUUp/f79c646+bG9vl7nbOqWemxsZPH36VObTpk2TuTqWc+pU/afqju10r/vt27cy3717d2V28+ZNufbnz58yr8I3JxCKcgKhKCcQinICoSgnEIpyAqEoJxCqwWx/0nuj/qXc3MrN5JShoSGZb9u2Tebuir96ZrD1XvHX1tYmc/W+ujmmm8G6qxMd9dr27Nkj1+7cudM9/LiDc745gVCUEwhFOYFQlBMIRTmBUJQTCEU5gVATup9TzVDrvarOHU+p9g66696ceuaYTl9fn8zdEY9uzumOkFTcXlE3//369avM3bGdivtM3Gfu/h5v3bpVmbW0tMi1teKbEwhFOYFQlBMIRTmBUJQTCEU5gVCUEwhV18Cunr2BEzkrnGgXLlyQ+cmTJ2U+ODhYmTU1Ncm16pq8UvTZr6X4M3fV5+Kem/t7cM9NzUHd83bXDzpu/qse/9SpU3Lt9u3ba3pOfHMCoSgnEIpyAqEoJxCKcgKhKCcQinICoWLPrX3//r3Mnz9/LvN79+7VvNbNrdRjl1JKY2OjzNVeVben0d0zuXDhQpm7eZ46H9bdYele9+joqMx7e3srs5GREbn24sWLMnf7Od2eTPW+zZ8/X669c+eOzAvn1gKTC+UEQlFOIBTlBEJRTiAU5QRC1TVKuXz5snzwAwcOVGZv3ryRaz98+CBz969xNa6YPXu2XKu2upXiRwJupKDec3e0ZVdXl8z7+/tl3tPTI/OPHz9WZu4zefz4scydpUuXVmbu+kF3ZKjbUuY+U3XF4PDwsFzrxl+FUQowuVBOIBTlBEJRTiAU5QRCUU4gFOUEQsk559jYmJxzbtiwQT642ppV75Vt9RyF6K6qc7PGeqm52Lt37+TaY8eOyXxgYEDmhw4dkvmCBQsqsxkzZsi1ak5ZSinLly+X+f379ysz976oKx9L8Z+5mu+WorfSubn4kydPZF6YcwKTC+UEQlFOIBTlBEJRTiAU5QRCUU4glJxzHjlyRM459+3bJx982bJllZnaH1eKPwrRXSenuJmX25+3ePFimS9atEjmai+r2odaSikvX76U+enTp2WurtkrpZRHjx5VZu4zu379el25ukKwnuNGS/FHgjqqJ+6xh4aGZN7R0cGcE5hMKCcQinICoSgnEIpyAqEoJxCKcgKh5KbKuXPnysVu3qdmlW5utWTJkpofuxS9/87t3Wtra5N5Z2enzN1zU/si3Z5Jt3dwx44dMu/u7pa5OnvW7al0n6k7L1jtyXSv212d6GaRbv+wmnOas5/tlZEdHR3jPye5CsAfQzmBUJQTCEU5gVCUEwhFOYFQcpTiRiXu389V/yIuxW8/clcEun/Lt7e315SV4reUue1qbr3atuWuulPbqkopZc6cOTK/ffu2zNVVem681draKnO3XU19Lu4oVXc0plvvrulTW/VaWlrk2ps3b8p806ZN4/6cb04gFOUEQlFOIBTlBEJRTiAU5QRCUU4glBz+rF69Wi5225OOHj1amS1cuFCuddfFua1Val7otg+5mZfajlaKn3Oq5+7WNjSMe4ri/zQ1NclcXfFXip5du21b7rm72XQ9WwzdY7vcbTlTc1R1nGgppcybN0/mVfjmBEJRTiAU5QRCUU4gFOUEQlFOIBTlBELJKwBLKfrMP+PMmTOV2cGDB+Xa169fy9ztyVRzLbcP1V0n5/Zzuj2Xah7ojll0c043a3QzXpW7x3bP3VHr3TGtjptNu78JtZ9z1apVcu3x48dlXkrhCkBgMqGcQCjKCYSinEAoygmEopxAKMoJhJJzzl+/fsnBlZsN1eP8+fMy379/v8xfvXpVmQ0PD8u1bl7n5phupqbOUHW/28373By0nrOI1Zm2pfj3pR5uv6Xbx+pm15s3b5Z5V1dXZdbb2yvX/gPMOYHJhHICoSgnEIpyAqEoJxCKcgKhKCcQakL3c6a6e/euzN3doO4eymfPnsm8s7OzMnPzPHeeLyYl5pzAZEI5gVCUEwhFOYFQlBMIRTmBUP/KUQoQhlEKMJlQTiAU5QRCUU4gFOUEQlFOIBTlBEJRTiAU5QRCUU4gFOUEQlFOIBTlBEJRTiAU5QRCVd9F9x/6PjkAE4ZvTiAU5QRCUU4gFOUEQlFOIBTlBEL9DRgW8qPu1lMTAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28,28), cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is more complex than MNIST, so we can expect to obtain lower accuracies using the same approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementing a Neural Network"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the images are in grayscale (single color channel), we must reshape them in this way: (N, height, size, 1). If the images were in RGB, the last number of the reshape sould be 3."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_valid = X_valid.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs) can achieve an awesome performance in complex tasks as image recognition, so they are the perfect choice for these type of tasks/problems.\n",
    "We will use Optuna for the hyperparameter optimization."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna\n",
    "The first hyperparameter to tune is the optimizer used during the model compilation. We pass 'Adam' and 'SGD' as options, each one with its learning rate (another hyperparameter) and, in the case of SGD, a momentum(also an hyperparameter)."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def create_optimizer(trial):\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer_name\", [\"Adam\", \"SGD\"])\n",
    "    if optimizer_name == \"Adam\":\n",
    "        adam_lr = trial.suggest_loguniform(\"adam_lr\", 1e-5, 1e-1)\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=adam_lr)\n",
    "    else:\n",
    "        sgd_lr = trial.suggest_loguniform(\"sgd_lr\", 1e-5, 1e-1)\n",
    "        sgd_momentum = trial.suggest_loguniform(\"sgd_momentum\", 1e-5, 1e-1)\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=sgd_lr, momentum=sgd_momentum)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the model in a function. It's a Sequential model, and we will tune the number of Conv2D and MaxPooling2D layers, in blocks, using a for loop. Also, the dropout rate used in the Dropout layers will be tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_blocks, dropout_rate):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, 7, activation='relu', padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(keras.layers.MaxPooling2D(2))\n",
    "    for layer in range(1,n_blocks):\n",
    "        model.add(keras.layers.Conv2D(128 * layer ,3,activation='relu', padding='same'))\n",
    "        model.add(keras.layers.Conv2D(128 * layer ,3,activation='relu', padding='same'))\n",
    "        model.add(keras.layers.MaxPooling2D(2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(dropout_rate))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(dropout_rate))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define the function to minimize, including some parameters for the fit process and the hyperparameters: the number of blocks in the CNN, the dropout rate and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # parameters for fitting the model\n",
    "    batch_size = 32\n",
    "    n_epochs = 20\n",
    "    # Defining the hyperparameter space\n",
    "    n_blocks = trial.suggest_int('n_blocks', 1, 4)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)\n",
    "    # Set the optimizer\n",
    "    optimizer =create_optimizer(trial)\n",
    "    # Build, compile and fit the model\n",
    "    model = build_model(n_blocks, dropout_rate)\n",
    "    # compile the model using the optimizer\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    # fit the model using validation data\n",
    "    history = model.fit(X_train, y_train, epochs=n_epochs, verbose=0, batch_size=batch_size, validation_data=(X_valid, y_valid))\n",
    "    # return 1-val_accuracy\n",
    "    return 1 - history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the process of optimization begins, during a number of trials defined in n_trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[I 2020-04-20 09:36:10,961] Finished trial#0 with value: 0.15619999170303345 with parameters: {'n_blocks': 3, 'dropout_rate': 0.27372050364126566, 'optimizer_name': 'SGD', 'sgd_lr': 0.03049963284655515, 'sgd_momentum': 0.016413531514489783}. Best is trial#0 with value: 0.15619999170303345.\n[I 2020-04-20 09:38:21,881] Finished trial#1 with value: 0.15420001745224 with parameters: {'n_blocks': 2, 'dropout_rate': 0.20674187887787226, 'optimizer_name': 'Adam', 'adam_lr': 0.008793440959350701}. Best is trial#1 with value: 0.15420001745224.\n[I 2020-04-20 09:39:06,406] Finished trial#2 with value: 0.1615999937057495 with parameters: {'n_blocks': 1, 'dropout_rate': 0.18516409167603987, 'optimizer_name': 'Adam', 'adam_lr': 3.6412598620922556e-05}. Best is trial#1 with value: 0.15420001745224.\n[I 2020-04-20 09:42:09,565] Finished trial#3 with value: 0.20260000228881836 with parameters: {'n_blocks': 3, 'dropout_rate': 0.09855691985286091, 'optimizer_name': 'Adam', 'adam_lr': 1.6807297326221457e-05}. Best is trial#1 with value: 0.15420001745224.\n[I 2020-04-20 09:44:43,111] Finished trial#4 with value: 0.4243999719619751 with parameters: {'n_blocks': 3, 'dropout_rate': 0.45487101621129544, 'optimizer_name': 'SGD', 'sgd_lr': 0.0009311233666276927, 'sgd_momentum': 0.018046745843091166}. Best is trial#1 with value: 0.15420001745224.\n[I 2020-04-20 09:46:30,665] Finished trial#5 with value: 0.4121999740600586 with parameters: {'n_blocks': 2, 'dropout_rate': 0.43191747830627875, 'optimizer_name': 'SGD', 'sgd_lr': 0.0006619451458474267, 'sgd_momentum': 1.1474991212655798e-05}. Best is trial#1 with value: 0.15420001745224.\n[I 2020-04-20 09:48:46,177] Finished trial#6 with value: 0.5850000083446503 with parameters: {'n_blocks': 4, 'dropout_rate': 0.46087722939721687, 'optimizer_name': 'SGD', 'sgd_lr': 0.0007987212756664986, 'sgd_momentum': 0.03537720647429225}. Best is trial#1 with value: 0.15420001745224.\n[I 2020-04-20 09:49:13,990] Finished trial#7 with value: 0.13120001554489136 with parameters: {'n_blocks': 1, 'dropout_rate': 0.18537432600121778, 'optimizer_name': 'Adam', 'adam_lr': 0.0017038051126661625}. Best is trial#7 with value: 0.13120001554489136.\n[I 2020-04-20 09:50:47,329] Finished trial#8 with value: 0.23799997568130493 with parameters: {'n_blocks': 2, 'dropout_rate': 0.11418430305540112, 'optimizer_name': 'SGD', 'sgd_lr': 0.0031015129232205853, 'sgd_momentum': 6.569380000118983e-05}. Best is trial#7 with value: 0.13120001554489136.\n[I 2020-04-20 09:52:22,960] Finished trial#9 with value: 0.25540000200271606 with parameters: {'n_blocks': 4, 'dropout_rate': 0.25698701565639365, 'optimizer_name': 'SGD', 'sgd_lr': 0.005765136252582268, 'sgd_momentum': 0.001180680566884788}. Best is trial#7 with value: 0.13120001554489136.\n[I 2020-04-20 09:52:51,042] Finished trial#10 with value: 0.13440001010894775 with parameters: {'n_blocks': 1, 'dropout_rate': 0.011546124065993646, 'optimizer_name': 'Adam', 'adam_lr': 8.777128662403712e-05}. Best is trial#7 with value: 0.13120001554489136.\n[I 2020-04-20 09:53:18,555] Finished trial#11 with value: 0.12339997291564941 with parameters: {'n_blocks': 1, 'dropout_rate': 0.014750278444854964, 'optimizer_name': 'Adam', 'adam_lr': 0.00035683135712712816}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 09:53:45,845] Finished trial#12 with value: 0.18140000104904175 with parameters: {'n_blocks': 1, 'dropout_rate': 0.0029245013476214554, 'optimizer_name': 'Adam', 'adam_lr': 1.0689377072850902e-05}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 09:54:13,416] Finished trial#13 with value: 0.12779998779296875 with parameters: {'n_blocks': 1, 'dropout_rate': 0.346514087877803, 'optimizer_name': 'Adam', 'adam_lr': 0.00017073789777379477}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 09:54:41,002] Finished trial#14 with value: 0.14079999923706055 with parameters: {'n_blocks': 1, 'dropout_rate': 0.3509875910533401, 'optimizer_name': 'Adam', 'adam_lr': 0.005699535207971975}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 09:55:42,901] Finished trial#15 with value: 0.17619997262954712 with parameters: {'n_blocks': 2, 'dropout_rate': 0.3506908372326753, 'optimizer_name': 'Adam', 'adam_lr': 0.010244561312633576}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 09:56:08,835] Finished trial#16 with value: 0.9099999964237213 with parameters: {'n_blocks': 1, 'dropout_rate': 0.34403144579892897, 'optimizer_name': 'Adam', 'adam_lr': 0.061731699049676216}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 09:57:11,023] Finished trial#17 with value: 0.12860000133514404 with parameters: {'n_blocks': 2, 'dropout_rate': 0.40149180189044587, 'optimizer_name': 'Adam', 'adam_lr': 0.00022213236091693186}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 09:57:36,873] Finished trial#18 with value: 0.12599998712539673 with parameters: {'n_blocks': 1, 'dropout_rate': 0.30391201476687957, 'optimizer_name': 'Adam', 'adam_lr': 0.0003840068188382371}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 09:58:30,955] Finished trial#19 with value: 0.12559998035430908 with parameters: {'n_blocks': 2, 'dropout_rate': 0.07541948567880172, 'optimizer_name': 'Adam', 'adam_lr': 0.0008212636290638092}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 09:59:31,028] Finished trial#20 with value: 0.12699997425079346 with parameters: {'n_blocks': 2, 'dropout_rate': 0.05640287832968143, 'optimizer_name': 'Adam', 'adam_lr': 0.0010082439083875128}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 09:59:56,479] Finished trial#21 with value: 0.14340001344680786 with parameters: {'n_blocks': 1, 'dropout_rate': 0.07120679820851095, 'optimizer_name': 'Adam', 'adam_lr': 0.0022653216508548594}. Best is trial#11 with value: 0.12339997291564941.\n[I 2020-04-20 10:00:54,499] Finished trial#22 with value: 0.12139999866485596 with parameters: {'n_blocks': 2, 'dropout_rate': 0.14742155017391867, 'optimizer_name': 'Adam', 'adam_lr': 0.0004911876631472576}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:02:07,882] Finished trial#23 with value: 0.15820002555847168 with parameters: {'n_blocks': 3, 'dropout_rate': 0.1379047465865239, 'optimizer_name': 'Adam', 'adam_lr': 4.600618602995041e-05}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:02:45,926] Finished trial#24 with value: 0.13419997692108154 with parameters: {'n_blocks': 2, 'dropout_rate': 0.03706308602649226, 'optimizer_name': 'Adam', 'adam_lr': 0.00046058475379985337}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:03:23,525] Finished trial#25 with value: 0.8984000012278557 with parameters: {'n_blocks': 2, 'dropout_rate': 0.13967270322370992, 'optimizer_name': 'Adam', 'adam_lr': 0.046955196571253625}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:04:35,113] Finished trial#26 with value: 0.14899998903274536 with parameters: {'n_blocks': 3, 'dropout_rate': 0.08268046122100531, 'optimizer_name': 'Adam', 'adam_lr': 0.004066355909845956}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:05:17,608] Finished trial#27 with value: 0.13239997625350952 with parameters: {'n_blocks': 2, 'dropout_rate': 0.027026939421253303, 'optimizer_name': 'Adam', 'adam_lr': 0.0005440755378727771}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:06:00,778] Finished trial#28 with value: 0.1363999843597412 with parameters: {'n_blocks': 2, 'dropout_rate': 0.14415939665312036, 'optimizer_name': 'Adam', 'adam_lr': 0.0001555085091402888}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:06:53,282] Finished trial#29 with value: 0.13559997081756592 with parameters: {'n_blocks': 3, 'dropout_rate': 0.22340727097491336, 'optimizer_name': 'Adam', 'adam_lr': 0.0009771665981985582}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:07:45,286] Finished trial#30 with value: 0.12980002164840698 with parameters: {'n_blocks': 3, 'dropout_rate': 0.05313402873490565, 'optimizer_name': 'Adam', 'adam_lr': 0.0009155452246367578}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:08:10,303] Finished trial#31 with value: 0.125 with parameters: {'n_blocks': 1, 'dropout_rate': 0.2847350561044238, 'optimizer_name': 'Adam', 'adam_lr': 0.0003166107380108987}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:08:35,981] Finished trial#32 with value: 0.1420000195503235 with parameters: {'n_blocks': 1, 'dropout_rate': 0.28479231366034513, 'optimizer_name': 'Adam', 'adam_lr': 8.636756679435133e-05}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:09:19,960] Finished trial#33 with value: 0.12480002641677856 with parameters: {'n_blocks': 2, 'dropout_rate': 0.2217900853139826, 'optimizer_name': 'Adam', 'adam_lr': 0.00025325212632538687}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:09:45,663] Finished trial#34 with value: 0.14219999313354492 with parameters: {'n_blocks': 1, 'dropout_rate': 0.23114417676752597, 'optimizer_name': 'Adam', 'adam_lr': 9.825200627409472e-05}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:10:30,543] Finished trial#35 with value: 0.17580002546310425 with parameters: {'n_blocks': 2, 'dropout_rate': 0.18597959613565823, 'optimizer_name': 'Adam', 'adam_lr': 2.7864935565559695e-05}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:10:56,286] Finished trial#36 with value: 0.22420001029968262 with parameters: {'n_blocks': 1, 'dropout_rate': 0.3118876395587943, 'optimizer_name': 'Adam', 'adam_lr': 0.023393200926488823}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:11:39,799] Finished trial#37 with value: 0.1218000054359436 with parameters: {'n_blocks': 2, 'dropout_rate': 0.25719976717489584, 'optimizer_name': 'Adam', 'adam_lr': 0.0003354596479698729}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:12:24,494] Finished trial#38 with value: 0.22439998388290405 with parameters: {'n_blocks': 2, 'dropout_rate': 0.2558963264817502, 'optimizer_name': 'SGD', 'sgd_lr': 0.010290354832676658, 'sgd_momentum': 0.007059641935814709}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:13:02,746] Finished trial#39 with value: 0.12660002708435059 with parameters: {'n_blocks': 2, 'dropout_rate': 0.20683314621799645, 'optimizer_name': 'Adam', 'adam_lr': 0.00026473356247301257}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:14:00,190] Finished trial#40 with value: 0.27079999446868896 with parameters: {'n_blocks': 3, 'dropout_rate': 0.15994153454128035, 'optimizer_name': 'SGD', 'sgd_lr': 0.002766288562024231, 'sgd_momentum': 0.0187821774634604}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:14:38,064] Finished trial#41 with value: 0.13940000534057617 with parameters: {'n_blocks': 2, 'dropout_rate': 0.28139145320316833, 'optimizer_name': 'Adam', 'adam_lr': 0.002032744252800305}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:15:16,159] Finished trial#42 with value: 0.12319999933242798 with parameters: {'n_blocks': 2, 'dropout_rate': 0.2361668638390009, 'optimizer_name': 'Adam', 'adam_lr': 0.0005527844553715407}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:15:54,280] Finished trial#43 with value: 0.12139999866485596 with parameters: {'n_blocks': 2, 'dropout_rate': 0.22698815352736426, 'optimizer_name': 'Adam', 'adam_lr': 0.0006613702588806914}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:16:32,177] Finished trial#44 with value: 0.1226000189781189 with parameters: {'n_blocks': 2, 'dropout_rate': 0.24224223086517246, 'optimizer_name': 'Adam', 'adam_lr': 0.0016336153354810812}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:17:10,050] Finished trial#45 with value: 0.1345999836921692 with parameters: {'n_blocks': 2, 'dropout_rate': 0.1854676591437445, 'optimizer_name': 'Adam', 'adam_lr': 0.003867149669481344}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:17:47,957] Finished trial#46 with value: 0.12940001487731934 with parameters: {'n_blocks': 2, 'dropout_rate': 0.2582274463165995, 'optimizer_name': 'Adam', 'adam_lr': 0.002762163181839897}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:18:45,609] Finished trial#47 with value: 0.8947999998927116 with parameters: {'n_blocks': 3, 'dropout_rate': 0.1681533982851377, 'optimizer_name': 'SGD', 'sgd_lr': 1.1128977555535412e-05, 'sgd_momentum': 0.00022865830322980186}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:19:23,532] Finished trial#48 with value: 0.1281999945640564 with parameters: {'n_blocks': 2, 'dropout_rate': 0.2428313920383441, 'optimizer_name': 'Adam', 'adam_lr': 0.001572515498406524}. Best is trial#22 with value: 0.12139999866485596.\n[I 2020-04-20 10:20:01,108] Finished trial#49 with value: 0.9006000012159348 with parameters: {'n_blocks': 2, 'dropout_rate': 0.198296338706934, 'optimizer_name': 'Adam', 'adam_lr': 0.009699453547871622}. Best is trial#22 with value: 0.12139999866485596.\nExecution time:2810.8388192653656\n"
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "start_time = time.time()\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Execution time:',time.time()- start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished, the best hyperparameters found can be accesed as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'n_blocks': 2,\n 'dropout_rate': 0.14742155017391867,\n 'optimizer_name': 'Adam',\n 'adam_lr': 0.0004911876631472576}"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can use them to create a new model that performs the best in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_blocks = int(study.best_params['n_blocks'])\n",
    "dropout_rate = study.best_params['dropout_rate']\n",
    "if study.best_params['optimizer_name'] == 'Adam':\n",
    "    optimizer = optimizer = keras.optimizers.Adam(learning_rate=study.best_params['adam_lr'])\n",
    "else:\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=study.best_params['sgd_lr'], momentum=study.best_params['sgd_momentum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the learning rate when a plateau is found is a useful technique to improve the model. It can be introduced in the CNN usign a keras callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is ready to compile and fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.0637 - accuracy: 0.972272/5000 [============>.................] - ETA: 0s - loss: 0.0663 - accuracy: 0.972464/5000 [=============>................] - ETA: 0s - loss: 0.0660 - accuracy: 0.972656/5000 [==============>...............] - ETA: 0s - loss: 0.0632 - accuracy: 0.972848/5000 [================>.............] - ETA: 0s - loss: 0.0647 - accuracy: 0.973040/5000 [=================>............] - ETA: 0s - loss: 0.0635 - accuracy: 0.973232/5000 [==================>...........] - ETA: 0s - loss: 0.0638 - accuracy: 0.973456/5000 [===================>..........] - ETA: 0s - loss: 0.0641 - accuracy: 0.973648/5000 [====================>.........] - ETA: 0s - loss: 0.0624 - accuracy: 0.973872/5000 [======================>.......] - ETA: 0s - loss: 0.0611 - accuracy: 0.974064/5000 [=======================>......] - ETA: 0s - loss: 0.0603 - accuracy: 0.974256/5000 [========================>.....] - ETA: 0s - loss: 0.0595 - accuracy: 0.974448/5000 [=========================>....] - ETA: 0s - loss: 0.0596 - accuracy: 0.974640/5000 [==========================>...] - ETA: 0s - loss: 0.0601 - accuracy: 0.974832/5000 [===========================>..] - ETA: 0s - loss: 0.0597 - accuracy: 0.975000/5000 [==============================] - 2s 404us/sample - loss: 0.0607 - accuracy: 0.9788 - val_loss: 0.5130 - val_accuracy: 0.8848\nEpoch 23/30\n  32/5000 [..............................] - ETA: 2s - loss: 0.0819 - accuracy: 0.96 224/5000 [>.............................] - ETA: 1s - loss: 0.0600 - accuracy: 0.97 416/5000 [=>............................] - ETA: 1s - loss: 0.0622 - accuracy: 0.98 608/5000 [==>...........................] - ETA: 1s - loss: 0.0591 - accuracy: 0.98 800/5000 [===>..........................] - ETA: 1s - loss: 0.0654 - accuracy: 0.98 992/5000 [====>.........................] - ETA: 1s - loss: 0.0632 - accuracy: 0.971184/5000 [======>.......................] - ETA: 1s - loss: 0.0632 - accuracy: 0.971376/5000 [=======>......................] - ETA: 1s - loss: 0.0623 - accuracy: 0.971568/5000 [========>.....................] - ETA: 0s - loss: 0.0624 - accuracy: 0.971792/5000 [=========>....................] - ETA: 0s - loss: 0.0627 - accuracy: 0.971984/5000 [==========>...................] - ETA: 0s - loss: 0.0647 - accuracy: 0.972144/5000 [===========>..................] - ETA: 0s - loss: 0.0633 - accuracy: 0.972336/5000 [=============>................] - ETA: 0s - loss: 0.0687 - accuracy: 0.972496/5000 [=============>................] - ETA: 0s - loss: 0.0664 - accuracy: 0.972688/5000 [===============>..............] - ETA: 0s - loss: 0.0683 - accuracy: 0.972816/5000 [===============>..............] - ETA: 0s - loss: 0.0686 - accuracy: 0.973008/5000 [=================>............] - ETA: 0s - loss: 0.0671 - accuracy: 0.973200/5000 [==================>...........] - ETA: 0s - loss: 0.0661 - accuracy: 0.973392/5000 [===================>..........] - ETA: 0s - loss: 0.0656 - accuracy: 0.973584/5000 [====================>.........] - ETA: 0s - loss: 0.0664 - accuracy: 0.973776/5000 [=====================>........] - ETA: 0s - loss: 0.0660 - accuracy: 0.973968/5000 [======================>.......] - ETA: 0s - loss: 0.0653 - accuracy: 0.974160/5000 [=======================>......] - ETA: 0s - loss: 0.0676 - accuracy: 0.974352/5000 [=========================>....] - ETA: 0s - loss: 0.0677 - accuracy: 0.974512/5000 [==========================>...] - ETA: 0s - loss: 0.0667 - accuracy: 0.974704/5000 [===========================>..] - ETA: 0s - loss: 0.0672 - accuracy: 0.974896/5000 [============================>.] - ETA: 0s - loss: 0.0666 - accuracy: 0.975000/5000 [==============================] - 2s 412us/sample - loss: 0.0658 - accuracy: 0.9784 - val_loss: 0.5052 - val_accuracy: 0.8850\nEpoch 24/30\n  32/5000 [..............................] - ETA: 1s - loss: 0.0695 - accuracy: 1.00 224/5000 [>.............................] - ETA: 1s - loss: 0.0582 - accuracy: 0.98 416/5000 [=>............................] - ETA: 1s - loss: 0.0701 - accuracy: 0.97 640/5000 [==>...........................] - ETA: 1s - loss: 0.0632 - accuracy: 0.97 864/5000 [====>.........................] - ETA: 1s - loss: 0.0706 - accuracy: 0.971056/5000 [=====>........................] - ETA: 1s - loss: 0.0704 - accuracy: 0.971248/5000 [======>.......................] - ETA: 1s - loss: 0.0707 - accuracy: 0.971440/5000 [=======>......................] - ETA: 0s - loss: 0.0660 - accuracy: 0.971632/5000 [========>.....................] - ETA: 0s - loss: 0.0638 - accuracy: 0.971824/5000 [=========>....................] - ETA: 0s - loss: 0.0641 - accuracy: 0.972016/5000 [===========>..................] - ETA: 0s - loss: 0.0659 - accuracy: 0.972240/5000 [============>.................] - ETA: 0s - loss: 0.0649 - accuracy: 0.972464/5000 [=============>................] - ETA: 0s - loss: 0.0644 - accuracy: 0.972688/5000 [===============>..............] - ETA: 0s - loss: 0.0676 - accuracy: 0.972880/5000 [================>.............] - ETA: 0s - loss: 0.0682 - accuracy: 0.973072/5000 [=================>............] - ETA: 0s - loss: 0.0661 - accuracy: 0.973264/5000 [==================>...........] - ETA: 0s - loss: 0.0672 - accuracy: 0.973488/5000 [===================>..........] - ETA: 0s - loss: 0.0666 - accuracy: 0.973712/5000 [=====================>........] - ETA: 0s - loss: 0.0653 - accuracy: 0.973904/5000 [======================>.......] - ETA: 0s - loss: 0.0639 - accuracy: 0.974128/5000 [=======================>......] - ETA: 0s - loss: 0.0632 - accuracy: 0.974352/5000 [=========================>....] - ETA: 0s - loss: 0.0631 - accuracy: 0.974544/5000 [==========================>...] - ETA: 0s - loss: 0.0622 - accuracy: 0.974736/5000 [===========================>..] - ETA: 0s - loss: 0.0612 - accuracy: 0.974928/5000 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.975000/5000 [==============================] - 2s 389us/sample - loss: 0.0610 - accuracy: 0.9798 - val_loss: 0.5053 - val_accuracy: 0.8836\nEpoch 25/30\n  32/5000 [..............................] - ETA: 1s - loss: 0.1375 - accuracy: 0.96 224/5000 [>.............................] - ETA: 1s - loss: 0.0461 - accuracy: 0.99 416/5000 [=>............................] - ETA: 1s - loss: 0.0417 - accuracy: 0.99 640/5000 [==>...........................] - ETA: 1s - loss: 0.0419 - accuracy: 0.99 864/5000 [====>.........................] - ETA: 1s - loss: 0.0411 - accuracy: 0.991056/5000 [=====>........................] - ETA: 1s - loss: 0.0400 - accuracy: 0.991248/5000 [======>.......................] - ETA: 1s - loss: 0.0399 - accuracy: 0.991440/5000 [=======>......................] - ETA: 0s - loss: 0.0453 - accuracy: 0.981632/5000 [========>.....................] - ETA: 0s - loss: 0.0436 - accuracy: 0.981824/5000 [=========>....................] - ETA: 0s - loss: 0.0458 - accuracy: 0.982016/5000 [===========>..................] - ETA: 0s - loss: 0.0459 - accuracy: 0.982240/5000 [============>.................] - ETA: 0s - loss: 0.0457 - accuracy: 0.982432/5000 [=============>................] - ETA: 0s - loss: 0.0458 - accuracy: 0.982624/5000 [==============>...............] - ETA: 0s - loss: 0.0452 - accuracy: 0.982816/5000 [===============>..............] - ETA: 0s - loss: 0.0467 - accuracy: 0.983008/5000 [=================>............] - ETA: 0s - loss: 0.0476 - accuracy: 0.983200/5000 [==================>...........] - ETA: 0s - loss: 0.0474 - accuracy: 0.983392/5000 [===================>..........] - ETA: 0s - loss: 0.0476 - accuracy: 0.983616/5000 [====================>.........] - ETA: 0s - loss: 0.0487 - accuracy: 0.983808/5000 [=====================>........] - ETA: 0s - loss: 0.0506 - accuracy: 0.984000/5000 [=======================>......] - ETA: 0s - loss: 0.0514 - accuracy: 0.984160/5000 [=======================>......] - ETA: 0s - loss: 0.0515 - accuracy: 0.984352/5000 [=========================>....] - ETA: 0s - loss: 0.0507 - accuracy: 0.984576/5000 [==========================>...] - ETA: 0s - loss: 0.0506 - accuracy: 0.984768/5000 [===========================>..] - ETA: 0s - loss: 0.0511 - accuracy: 0.984960/5000 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.985000/5000 [==============================] - 2s 400us/sample - loss: 0.0518 - accuracy: 0.9838 - val_loss: 0.5129 - val_accuracy: 0.8832\nEpoch 26/30\n  32/5000 [..............................] - ETA: 2s - loss: 0.0363 - accuracy: 0.96 224/5000 [>.............................] - ETA: 1s - loss: 0.0418 - accuracy: 0.97 416/5000 [=>............................] - ETA: 1s - loss: 0.0484 - accuracy: 0.97 608/5000 [==>...........................] - ETA: 1s - loss: 0.0476 - accuracy: 0.97 704/5000 [===>..........................] - ETA: 1s - loss: 0.0519 - accuracy: 0.97 896/5000 [====>.........................] - ETA: 1s - loss: 0.0516 - accuracy: 0.971088/5000 [=====>........................] - ETA: 1s - loss: 0.0524 - accuracy: 0.971280/5000 [======>.......................] - ETA: 1s - loss: 0.0559 - accuracy: 0.971504/5000 [========>.....................] - ETA: 1s - loss: 0.0556 - accuracy: 0.971696/5000 [=========>....................] - ETA: 0s - loss: 0.0619 - accuracy: 0.971888/5000 [==========>...................] - ETA: 0s - loss: 0.0631 - accuracy: 0.972080/5000 [===========>..................] - ETA: 0s - loss: 0.0631 - accuracy: 0.972272/5000 [============>.................] - ETA: 0s - loss: 0.0620 - accuracy: 0.972464/5000 [=============>................] - ETA: 0s - loss: 0.0612 - accuracy: 0.972656/5000 [==============>...............] - ETA: 0s - loss: 0.0612 - accuracy: 0.972848/5000 [================>.............] - ETA: 0s - loss: 0.0594 - accuracy: 0.973072/5000 [=================>............] - ETA: 0s - loss: 0.0619 - accuracy: 0.973264/5000 [==================>...........] - ETA: 0s - loss: 0.0611 - accuracy: 0.973456/5000 [===================>..........] - ETA: 0s - loss: 0.0601 - accuracy: 0.973648/5000 [====================>.........] - ETA: 0s - loss: 0.0587 - accuracy: 0.973840/5000 [======================>.......] - ETA: 0s - loss: 0.0577 - accuracy: 0.974000/5000 [=======================>......] - ETA: 0s - loss: 0.0567 - accuracy: 0.984160/5000 [=======================>......] - ETA: 0s - loss: 0.0583 - accuracy: 0.974352/5000 [=========================>....] - ETA: 0s - loss: 0.0600 - accuracy: 0.974544/5000 [==========================>...] - ETA: 0s - loss: 0.0599 - accuracy: 0.974736/5000 [===========================>..] - ETA: 0s - loss: 0.0595 - accuracy: 0.974896/5000 [============================>.] - ETA: 0s - loss: 0.0590 - accuracy: 0.975000/5000 [==============================] - 2s 409us/sample - loss: 0.0598 - accuracy: 0.9790 - val_loss: 0.5242 - val_accuracy: 0.8814\nEpoch 27/30\n  32/5000 [..............................] - ETA: 1s - loss: 0.0227 - accuracy: 1.00 224/5000 [>.............................] - ETA: 1s - loss: 0.0348 - accuracy: 0.99 416/5000 [=>............................] - ETA: 1s - loss: 0.0464 - accuracy: 0.98 640/5000 [==>...........................] - ETA: 1s - loss: 0.0429 - accuracy: 0.98 864/5000 [====>.........................] - ETA: 1s - loss: 0.0421 - accuracy: 0.981056/5000 [=====>........................] - ETA: 1s - loss: 0.0458 - accuracy: 0.981248/5000 [======>.......................] - ETA: 1s - loss: 0.0442 - accuracy: 0.981472/5000 [=======>......................] - ETA: 0s - loss: 0.0447 - accuracy: 0.981696/5000 [=========>....................] - ETA: 0s - loss: 0.0488 - accuracy: 0.981888/5000 [==========>...................] - ETA: 0s - loss: 0.0496 - accuracy: 0.982112/5000 [===========>..................] - ETA: 0s - loss: 0.0470 - accuracy: 0.982272/5000 [============>.................] - ETA: 0s - loss: 0.0477 - accuracy: 0.982400/5000 [=============>................] - ETA: 0s - loss: 0.0489 - accuracy: 0.982592/5000 [==============>...............] - ETA: 0s - loss: 0.0480 - accuracy: 0.982784/5000 [===============>..............] - ETA: 0s - loss: 0.0495 - accuracy: 0.982976/5000 [================>.............] - ETA: 0s - loss: 0.0503 - accuracy: 0.983200/5000 [==================>...........] - ETA: 0s - loss: 0.0488 - accuracy: 0.983424/5000 [===================>..........] - ETA: 0s - loss: 0.0481 - accuracy: 0.983648/5000 [====================>.........] - ETA: 0s - loss: 0.0480 - accuracy: 0.983840/5000 [======================>.......] - ETA: 0s - loss: 0.0480 - accuracy: 0.984032/5000 [=======================>......] - ETA: 0s - loss: 0.0480 - accuracy: 0.984256/5000 [========================>.....] - ETA: 0s - loss: 0.0483 - accuracy: 0.984448/5000 [=========================>....] - ETA: 0s - loss: 0.0478 - accuracy: 0.984608/5000 [==========================>...] - ETA: 0s - loss: 0.0485 - accuracy: 0.984800/5000 [===========================>..] - ETA: 0s - loss: 0.0478 - accuracy: 0.984992/5000 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.985000/5000 [==============================] - 2s 401us/sample - loss: 0.0488 - accuracy: 0.9828 - val_loss: 0.5263 - val_accuracy: 0.8822\nEpoch 28/30\n  32/5000 [..............................] - ETA: 2s - loss: 0.1462 - accuracy: 0.93 224/5000 [>.............................] - ETA: 1s - loss: 0.0752 - accuracy: 0.96 416/5000 [=>............................] - ETA: 1s - loss: 0.0550 - accuracy: 0.98 608/5000 [==>...........................] - ETA: 1s - loss: 0.0604 - accuracy: 0.98 800/5000 [===>..........................] - ETA: 1s - loss: 0.0594 - accuracy: 0.98 992/5000 [====>.........................] - ETA: 1s - loss: 0.0559 - accuracy: 0.981216/5000 [======>.......................] - ETA: 1s - loss: 0.0550 - accuracy: 0.981440/5000 [=======>......................] - ETA: 0s - loss: 0.0515 - accuracy: 0.981664/5000 [========>.....................] - ETA: 0s - loss: 0.0535 - accuracy: 0.981856/5000 [==========>...................] - ETA: 0s - loss: 0.0513 - accuracy: 0.982080/5000 [===========>..................] - ETA: 0s - loss: 0.0487 - accuracy: 0.982272/5000 [============>.................] - ETA: 0s - loss: 0.0472 - accuracy: 0.982464/5000 [=============>................] - ETA: 0s - loss: 0.0477 - accuracy: 0.982656/5000 [==============>...............] - ETA: 0s - loss: 0.0472 - accuracy: 0.982848/5000 [================>.............] - ETA: 0s - loss: 0.0495 - accuracy: 0.983072/5000 [=================>............] - ETA: 0s - loss: 0.0480 - accuracy: 0.983296/5000 [==================>...........] - ETA: 0s - loss: 0.0477 - accuracy: 0.983488/5000 [===================>..........] - ETA: 0s - loss: 0.0479 - accuracy: 0.983680/5000 [=====================>........] - ETA: 0s - loss: 0.0480 - accuracy: 0.983904/5000 [======================>.......] - ETA: 0s - loss: 0.0484 - accuracy: 0.984096/5000 [=======================>......] - ETA: 0s - loss: 0.0475 - accuracy: 0.984288/5000 [========================>.....] - ETA: 0s - loss: 0.0469 - accuracy: 0.984480/5000 [=========================>....] - ETA: 0s - loss: 0.0479 - accuracy: 0.984672/5000 [===========================>..] - ETA: 0s - loss: 0.0475 - accuracy: 0.984864/5000 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.985000/5000 [==============================] - 2s 397us/sample - loss: 0.0484 - accuracy: 0.9830 - val_loss: 0.5407 - val_accuracy: 0.8806\nEpoch 29/30\n  32/5000 [..............................] - ETA: 2s - loss: 0.0140 - accuracy: 1.00 224/5000 [>.............................] - ETA: 1s - loss: 0.0492 - accuracy: 0.98 416/5000 [=>............................] - ETA: 1s - loss: 0.0539 - accuracy: 0.97 608/5000 [==>...........................] - ETA: 1s - loss: 0.0472 - accuracy: 0.98 800/5000 [===>..........................] - ETA: 1s - loss: 0.0432 - accuracy: 0.981024/5000 [=====>........................] - ETA: 1s - loss: 0.0391 - accuracy: 0.981248/5000 [======>.......................] - ETA: 1s - loss: 0.0405 - accuracy: 0.981440/5000 [=======>......................] - ETA: 0s - loss: 0.0450 - accuracy: 0.981632/5000 [========>.....................] - ETA: 0s - loss: 0.0427 - accuracy: 0.981824/5000 [=========>....................] - ETA: 0s - loss: 0.0459 - accuracy: 0.982048/5000 [===========>..................] - ETA: 0s - loss: 0.0445 - accuracy: 0.982240/5000 [============>.................] - ETA: 0s - loss: 0.0448 - accuracy: 0.982464/5000 [=============>................] - ETA: 0s - loss: 0.0439 - accuracy: 0.982688/5000 [===============>..............] - ETA: 0s - loss: 0.0440 - accuracy: 0.982816/5000 [===============>..............] - ETA: 0s - loss: 0.0435 - accuracy: 0.983008/5000 [=================>............] - ETA: 0s - loss: 0.0439 - accuracy: 0.983200/5000 [==================>...........] - ETA: 0s - loss: 0.0439 - accuracy: 0.983392/5000 [===================>..........] - ETA: 0s - loss: 0.0429 - accuracy: 0.983584/5000 [====================>.........] - ETA: 0s - loss: 0.0436 - accuracy: 0.983808/5000 [=====================>........] - ETA: 0s - loss: 0.0424 - accuracy: 0.984000/5000 [=======================>......] - ETA: 0s - loss: 0.0415 - accuracy: 0.984192/5000 [========================>.....] - ETA: 0s - loss: 0.0419 - accuracy: 0.984384/5000 [=========================>....] - ETA: 0s - loss: 0.0436 - accuracy: 0.984576/5000 [==========================>...] - ETA: 0s - loss: 0.0461 - accuracy: 0.984768/5000 [===========================>..] - ETA: 0s - loss: 0.0460 - accuracy: 0.984960/5000 [============================>.] - ETA: 0s - loss: 0.0454 - accuracy: 0.985000/5000 [==============================] - 2s 405us/sample - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.5403 - val_accuracy: 0.8816\nEpoch 30/30\n  32/5000 [..............................] - ETA: 2s - loss: 0.0550 - accuracy: 0.96 224/5000 [>.............................] - ETA: 1s - loss: 0.0298 - accuracy: 0.98 320/5000 [>.............................] - ETA: 1s - loss: 0.0316 - accuracy: 0.99 512/5000 [==>...........................] - ETA: 1s - loss: 0.0376 - accuracy: 0.98 704/5000 [===>..........................] - ETA: 1s - loss: 0.0418 - accuracy: 0.98 896/5000 [====>.........................] - ETA: 1s - loss: 0.0408 - accuracy: 0.981088/5000 [=====>........................] - ETA: 1s - loss: 0.0396 - accuracy: 0.981280/5000 [======>.......................] - ETA: 1s - loss: 0.0393 - accuracy: 0.981472/5000 [=======>......................] - ETA: 1s - loss: 0.0403 - accuracy: 0.981664/5000 [========>.....................] - ETA: 1s - loss: 0.0428 - accuracy: 0.981856/5000 [==========>...................] - ETA: 0s - loss: 0.0410 - accuracy: 0.982048/5000 [===========>..................] - ETA: 0s - loss: 0.0416 - accuracy: 0.982272/5000 [============>.................] - ETA: 0s - loss: 0.0426 - accuracy: 0.982496/5000 [=============>................] - ETA: 0s - loss: 0.0425 - accuracy: 0.982688/5000 [===============>..............] - ETA: 0s - loss: 0.0433 - accuracy: 0.982880/5000 [================>.............] - ETA: 0s - loss: 0.0458 - accuracy: 0.983104/5000 [=================>............] - ETA: 0s - loss: 0.0440 - accuracy: 0.983296/5000 [==================>...........] - ETA: 0s - loss: 0.0432 - accuracy: 0.983456/5000 [===================>..........] - ETA: 0s - loss: 0.0426 - accuracy: 0.983648/5000 [====================>.........] - ETA: 0s - loss: 0.0422 - accuracy: 0.983840/5000 [======================>.......] - ETA: 0s - loss: 0.0408 - accuracy: 0.984032/5000 [=======================>......] - ETA: 0s - loss: 0.0396 - accuracy: 0.984256/5000 [========================>.....] - ETA: 0s - loss: 0.0397 - accuracy: 0.984448/5000 [=========================>....] - ETA: 0s - loss: 0.0407 - accuracy: 0.984640/5000 [==========================>...] - ETA: 0s - loss: 0.0406 - accuracy: 0.984864/5000 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.985000/5000 [==============================] - 2s 407us/sample - loss: 0.0419 - accuracy: 0.9846 - val_loss: 0.5446 - val_accuracy: 0.8824\n"
    }
   ],
   "source": [
    "# define the model with the best hyperparameters\n",
    "model = build_model(conv_blocks, dropout_rate)\n",
    "n_epochs = 30\n",
    "batch_size = 32\n",
    "# review the model\n",
    "model.summary()\n",
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "# fit the model, with validation data and the reduce_lr callback\n",
    "history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size, validation_data=(X_valid, y_valid), callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the evolution of accuracies and losses with training epochs:"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"306.677344pt\" version=\"1.1\" viewBox=\"0 0 483.768446 306.677344\" width=\"483.768446pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 306.677344 \r\nL 483.768446 306.677344 \r\nL 483.768446 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 282.799219 \r\nL 476.503125 282.799219 \r\nL 476.503125 10.999219 \r\nL 30.103125 10.999219 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 50.394034 282.799219 \r\nL 50.394034 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mced22555f5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.394034\" xlink:href=\"#mced22555f5\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(47.212784 297.397656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 120.362686 282.799219 \r\nL 120.362686 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"120.362686\" xlink:href=\"#mced22555f5\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(117.181436 297.397656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 190.331338 282.799219 \r\nL 190.331338 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"190.331338\" xlink:href=\"#mced22555f5\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(183.968838 297.397656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 260.29999 282.799219 \r\nL 260.29999 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"260.29999\" xlink:href=\"#mced22555f5\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(253.93749 297.397656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 330.268642 282.799219 \r\nL 330.268642 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"330.268642\" xlink:href=\"#mced22555f5\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(323.906142 297.397656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 400.237294 282.799219 \r\nL 400.237294 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"400.237294\" xlink:href=\"#mced22555f5\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(393.874794 297.397656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 470.205946 282.799219 \r\nL 470.205946 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"470.205946\" xlink:href=\"#mced22555f5\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 30 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(463.843446 297.397656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 30.103125 282.799219 \r\nL 476.503125 282.799219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_16\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m6e378c0780\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m6e378c0780\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.0 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 286.598437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_17\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 30.103125 228.439219 \r\nL 476.503125 228.439219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m6e378c0780\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.2 -->\r\n      <g transform=\"translate(7.2 232.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_19\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 30.103125 174.079219 \r\nL 476.503125 174.079219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m6e378c0780\" y=\"174.079219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 177.878437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 30.103125 119.719219 \r\nL 476.503125 119.719219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m6e378c0780\" y=\"119.719219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 123.518437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 30.103125 65.359219 \r\nL 476.503125 65.359219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m6e378c0780\" y=\"65.359219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 69.158437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_25\">\r\n      <path clip-path=\"url(#pb5a94388f8)\" d=\"M 30.103125 10.999219 \r\nL 476.503125 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_26\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m6e378c0780\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_27\">\r\n    <path clip-path=\"url(#pb5a94388f8)\" d=\"M 51.318116 -1 \r\nL 64.387764 116.951479 \r\nL 78.381495 142.468421 \r\nL 92.375225 160.493501 \r\nL 106.368956 173.298927 \r\nL 120.362686 181.342793 \r\nL 134.356417 190.220596 \r\nL 148.350147 199.682193 \r\nL 162.343877 202.490485 \r\nL 176.337608 211.679636 \r\nL 190.331338 214.614753 \r\nL 204.325069 220.553984 \r\nL 218.318799 228.333585 \r\nL 232.312529 233.6585 \r\nL 246.30626 235.715865 \r\nL 260.29999 237.925935 \r\nL 274.293721 239.574039 \r\nL 288.287451 247.731421 \r\nL 302.281181 258.085452 \r\nL 316.274912 262.602987 \r\nL 330.268642 264.602116 \r\nL 344.262373 266.312805 \r\nL 358.256103 264.90328 \r\nL 372.249833 266.206781 \r\nL 386.243564 268.732778 \r\nL 400.237294 266.558461 \r\nL 414.231025 269.547904 \r\nL 428.224755 269.646511 \r\nL 442.218486 270.478339 \r\nL 456.212216 271.40983 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_28\">\r\n    <path clip-path=\"url(#pb5a94388f8)\" d=\"M 50.394034 115.261698 \r\nL 64.387764 69.164415 \r\nL 78.381495 60.249386 \r\nL 92.375225 55.139541 \r\nL 106.368956 49.105584 \r\nL 120.362686 46.876827 \r\nL 134.356417 44.484979 \r\nL 148.350147 39.81002 \r\nL 162.343877 40.081817 \r\nL 176.337608 37.037654 \r\nL 190.331338 35.243784 \r\nL 204.325069 33.015011 \r\nL 218.318799 30.949344 \r\nL 232.312529 28.231331 \r\nL 246.30626 27.905181 \r\nL 260.29999 27.089776 \r\nL 274.293721 26.654905 \r\nL 288.287451 23.284576 \r\nL 302.281181 20.729653 \r\nL 316.274912 17.631138 \r\nL 330.268642 17.848581 \r\nL 344.262373 16.761379 \r\nL 358.256103 16.870101 \r\nL 372.249833 16.489583 \r\nL 386.243564 15.40238 \r\nL 400.237294 16.707026 \r\nL 414.231025 15.674177 \r\nL 428.224755 15.619824 \r\nL 442.218486 14.750066 \r\nL 456.212216 15.184937 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_29\">\r\n    <path clip-path=\"url(#pb5a94388f8)\" d=\"M 50.394034 122.594995 \r\nL 64.387764 147.438491 \r\nL 78.381495 153.498017 \r\nL 92.375225 161.963539 \r\nL 106.368956 172.29188 \r\nL 120.362686 169.445423 \r\nL 134.356417 167.84374 \r\nL 148.350147 181.043592 \r\nL 162.343877 179.877664 \r\nL 176.337608 175.748614 \r\nL 190.331338 178.681796 \r\nL 204.325069 174.94414 \r\nL 218.318799 173.165494 \r\nL 232.312529 158.925608 \r\nL 246.30626 162.177354 \r\nL 260.29999 160.521931 \r\nL 274.293721 168.849441 \r\nL 288.287451 150.201007 \r\nL 302.281181 154.881148 \r\nL 316.274912 154.577611 \r\nL 330.268642 149.493897 \r\nL 344.262373 143.368959 \r\nL 358.256103 145.497694 \r\nL 372.249833 145.44741 \r\nL 386.243564 143.392806 \r\nL 400.237294 140.318675 \r\nL 414.231025 139.760023 \r\nL 428.224755 135.82746 \r\nL 442.218486 135.940524 \r\nL 456.212216 134.790189 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_30\">\r\n    <path clip-path=\"url(#pb5a94388f8)\" d=\"M 50.394034 69.164415 \r\nL 64.387764 58.781666 \r\nL 78.381495 58.4555 \r\nL 92.375225 55.193894 \r\nL 106.368956 50.084064 \r\nL 120.362686 50.464583 \r\nL 134.356417 49.703546 \r\nL 148.350147 47.583494 \r\nL 162.343877 46.441939 \r\nL 176.337608 48.725066 \r\nL 190.331338 46.115774 \r\nL 204.325069 47.257345 \r\nL 218.318799 43.61522 \r\nL 232.312529 47.529141 \r\nL 246.30626 44.484979 \r\nL 260.29999 46.224496 \r\nL 274.293721 45.572181 \r\nL 288.287451 44.430626 \r\nL 302.281181 42.473665 \r\nL 316.274912 42.528018 \r\nL 330.268642 43.071611 \r\nL 344.262373 42.310574 \r\nL 358.256103 42.256221 \r\nL 372.249833 42.63674 \r\nL 386.243564 42.745462 \r\nL 400.237294 43.234702 \r\nL 414.231025 43.017258 \r\nL 428.224755 43.452145 \r\nL 442.218486 43.180333 \r\nL 456.212216 42.962905 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_31\">\r\n    <path clip-path=\"url(#pb5a94388f8)\" d=\"M 50.394034 282.665714 \r\nL 64.387764 282.665714 \r\nL 78.381495 282.665714 \r\nL 92.375225 282.665714 \r\nL 106.368956 282.665714 \r\nL 120.362686 282.665714 \r\nL 134.356417 282.665714 \r\nL 148.350147 282.665714 \r\nL 162.343877 282.665714 \r\nL 176.337608 282.665714 \r\nL 190.331338 282.665714 \r\nL 204.325069 282.665714 \r\nL 218.318799 282.665714 \r\nL 232.312529 282.665714 \r\nL 246.30626 282.665714 \r\nL 260.29999 282.665714 \r\nL 274.293721 282.665714 \r\nL 288.287451 282.665714 \r\nL 302.281181 282.785868 \r\nL 316.274912 282.785868 \r\nL 330.268642 282.785868 \r\nL 344.262373 282.785868 \r\nL 358.256103 282.785868 \r\nL 372.249833 282.785868 \r\nL 386.243564 282.785868 \r\nL 400.237294 282.785868 \r\nL 414.231025 282.785868 \r\nL 428.224755 282.785868 \r\nL 442.218486 282.797884 \r\nL 456.212216 282.797884 \r\n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 282.799219 \r\nL 30.103125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 476.503125 282.799219 \r\nL 476.503125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 282.799219 \r\nL 476.503125 282.799219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 10.999219 \r\nL 476.503125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 37.103125 277.799219 \r\nL 134.046875 277.799219 \r\nQ 136.046875 277.799219 136.046875 275.799219 \r\nL 136.046875 202.852344 \r\nQ 136.046875 200.852344 134.046875 200.852344 \r\nL 37.103125 200.852344 \r\nQ 35.103125 200.852344 35.103125 202.852344 \r\nL 35.103125 275.799219 \r\nQ 35.103125 277.799219 37.103125 277.799219 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_32\">\r\n     <path d=\"M 39.103125 208.950781 \r\nL 59.103125 208.950781 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_33\"/>\r\n    <g id=\"text_14\">\r\n     <!-- loss -->\r\n     <defs>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n     </defs>\r\n     <g transform=\"translate(67.103125 212.450781)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_34\">\r\n     <path d=\"M 39.103125 223.628906 \r\nL 59.103125 223.628906 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_35\"/>\r\n    <g id=\"text_15\">\r\n     <!-- accuracy -->\r\n     <defs>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n      <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n     </defs>\r\n     <g transform=\"translate(67.103125 227.128906)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_36\">\r\n     <path d=\"M 39.103125 238.307031 \r\nL 59.103125 238.307031 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_37\"/>\r\n    <g id=\"text_16\">\r\n     <!-- val_loss -->\r\n     <defs>\r\n      <path d=\"M 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 8.796875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nL 35.6875 0 \r\nL 23.484375 0 \r\nz\r\n\" id=\"DejaVuSans-118\"/>\r\n      <path d=\"M 50.984375 -16.609375 \r\nL 50.984375 -23.578125 \r\nL -0.984375 -23.578125 \r\nL -0.984375 -16.609375 \r\nz\r\n\" id=\"DejaVuSans-95\"/>\r\n     </defs>\r\n     <g transform=\"translate(67.103125 241.807031)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"226.025391\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"287.207031\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_38\">\r\n     <path d=\"M 39.103125 253.263281 \r\nL 59.103125 253.263281 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_39\"/>\r\n    <g id=\"text_17\">\r\n     <!-- val_accuracy -->\r\n     <g transform=\"translate(67.103125 256.763281)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"259.521484\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"369.482422\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"432.861328\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"473.974609\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"535.253906\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"590.234375\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_40\">\r\n     <path d=\"M 39.103125 268.219531 \r\nL 59.103125 268.219531 \r\n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_41\"/>\r\n    <g id=\"text_18\">\r\n     <!-- lr -->\r\n     <g transform=\"translate(67.103125 271.719531)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-114\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pb5a94388f8\">\r\n   <rect height=\"271.8\" width=\"446.4\" x=\"30.103125\" y=\"10.999219\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, evaluate the CNN with the test set:"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "32/10000 [..............................] - ETA: 35s - loss: 338.3814 - accuracy: 0.781  288/10000 [..............................] - ETA: 5s - loss: 117.3089 - accuracy: 0.87  704/10000 [=>............................] - ETA: 2s - loss: 110.0589 - accuracy: 0.86 1152/10000 [==>...........................] - ETA: 2s - loss: 117.3985 - accuracy: 0.87 1600/10000 [===>..........................] - ETA: 1s - loss: 110.3156 - accuracy: 0.87 2048/10000 [=====>........................] - ETA: 1s - loss: 111.5188 - accuracy: 0.87 2496/10000 [======>.......................] - ETA: 1s - loss: 107.4503 - accuracy: 0.87 2944/10000 [=======>......................] - ETA: 1s - loss: 111.3919 - accuracy: 0.87 3392/10000 [=========>....................] - ETA: 1s - loss: 113.3695 - accuracy: 0.86 3680/10000 [==========>...................] - ETA: 1s - loss: 113.6461 - accuracy: 0.86 4032/10000 [===========>..................] - ETA: 0s - loss: 113.6179 - accuracy: 0.86 4352/10000 [============>.................] - ETA: 0s - loss: 112.2638 - accuracy: 0.86 4800/10000 [=============>................] - ETA: 0s - loss: 110.8660 - accuracy: 0.86 5216/10000 [==============>...............] - ETA: 0s - loss: 114.1986 - accuracy: 0.86 5664/10000 [===============>..............] - ETA: 0s - loss: 114.8936 - accuracy: 0.86 6144/10000 [=================>............] - ETA: 0s - loss: 114.8449 - accuracy: 0.86 6592/10000 [==================>...........] - ETA: 0s - loss: 114.8195 - accuracy: 0.86 7040/10000 [====================>.........] - ETA: 0s - loss: 114.0676 - accuracy: 0.86 7456/10000 [=====================>........] - ETA: 0s - loss: 113.2097 - accuracy: 0.86 7872/10000 [======================>.......] - ETA: 0s - loss: 109.8448 - accuracy: 0.86 8288/10000 [=======================>......] - ETA: 0s - loss: 108.9334 - accuracy: 0.86 8704/10000 [=========================>....] - ETA: 0s - loss: 107.9043 - accuracy: 0.86 9152/10000 [==========================>...] - ETA: 0s - loss: 108.4422 - accuracy: 0.86 9568/10000 [===========================>..] - ETA: 0s - loss: 110.1566 - accuracy: 0.86 9984/10000 [============================>.] - ETA: 0s - loss: 110.2841 - accuracy: 0.8610000/10000 [==============================] - 1s 138us/sample - loss: 110.1692 - accuracy: 0.8665\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[110.16916485900879, 0.8665]"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ]
}